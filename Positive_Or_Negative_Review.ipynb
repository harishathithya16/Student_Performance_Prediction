{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nM3wRMZggXP",
        "outputId": "98ca6672-cd21-4d35-e598-25e28c33053a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 88ms/step - accuracy: 0.6658 - loss: 0.5842 - val_accuracy: 0.8736 - val_loss: 0.3105\n",
            "Epoch 2/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 87ms/step - accuracy: 0.8999 - loss: 0.2604 - val_accuracy: 0.8634 - val_loss: 0.3544\n",
            "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.8603 - loss: 0.3764\n",
            "Test Accuracy : 0.8604400157928467\n",
            "Enter a movie review: okay film\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
            "Sentiment: Negative ğŸ˜\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(10000, 32),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=2,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test Accuracy :\", acc)\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "def encode_review(text):\n",
        "    words = text.lower().split()\n",
        "    encoded = [1]\n",
        "    for word in words:\n",
        "        encoded.append(word_index.get(word, 2))\n",
        "    return pad_sequences([encoded], maxlen=200)\n",
        "\n",
        "test_text = input(\"Enter a movie review: \")\n",
        "encoded = encode_review(test_text)\n",
        "prediction = model.predict(encoded)\n",
        "\n",
        "if prediction[0][0] > 0.5:\n",
        "    print(\"Sentiment: Positive ğŸ˜Š\")\n",
        "else:\n",
        "    print(\"Sentiment: Negative ğŸ˜\")\n"
      ]
    }
  ]
}